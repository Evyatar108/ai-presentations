# Meeting Highlights Cost Optimization – Your Key Contributions (Aug–Oct 2025)

You personally led critical optimizations to reduce the **Cost of Goods Sold (COGS)** and GPU usage for the Meeting Highlights feature, enabling its **private preview** and paving the way for **worldwide GA rollout**. In summary, you redesigned the LLM prompting pipeline from a **four-step process** down to a **single unified prompt**, dramatically cutting GPU requirements by an estimated **70–80%** with **minimal impact on output quality**. These efforts – executed in **September–October 2025** – unblocked the feature's release by bringing projected GPU needs from roughly **600 A100 GPUs** down to around **130 GPUs**, meeting capacity constraints. Below is a detailed breakdown of your contributions and their impact:

## **Single-Prompt Architecture for Meeting Highlights** (Sept 2025)

**You spearheaded a major architectural change** by collapsing the Meeting Highlights generation pipeline from **four separate GPT-4 calls into one**. The original implementation (V1) required multiple sequential LLM requests per meeting (e.g. identifying key moments, generating summaries for each, etc.), which was costly. In late August, the team identified this as a primary cost driver and planned a "**one-prompt**" solution. You took ownership of designing and implementing this **single-pass prompt (V2)** in September. By **September 30, 2025**, you had this new unified prompt **code ready in a PR** (pull request) and began testing it locally on the new **TMR service** (Teams Meeting Recap service) instead of the older Polymer pipeline. This new prompt encapsulates all highlight-generation tasks in one go. As noted by your manager Eli Lekhtser in a team sync, *"V2 is a compact prompt with only one LLM request… Evyatar was able to reduce the amount of input and output tokens, so it **dramatically reduces the GPUs** needed"*. In short, **this single-prompt refactoring slashed LLM invocation count per meeting from 4 down to 1**, directly reducing computational load.

## **Prompt Optimization & Token Reduction** (Sept–Oct 2025)

Alongside merging the calls, you **optimized the prompt content to be more efficient**, cutting down the total tokens processed. By streamlining the instructions and data fed into the model (and focusing on essential transcript content), you **reduced both input and output token counts** per meeting. This optimization was crucial because **fewer tokens** directly mean **lower Azure OpenAI usage costs and less GPU time** per request. In the capacity review, the team reported that **your prompt changes "reduce COGS by half or more"** relative to the initial approach. In practice, the **GPU demand dropped sharply** – from an initially estimated **~600 GPUs needed for GA** to a manageable level (on the order of a few hundred or less) after your improvements. By late September, **Eli** highlighted that the **bottleneck for releasing Meeting Highlights was purely awaiting your cost fixes** – *"even with new capacity, we cannot release… the bottleneck is Evyatar finishing his changes to reduce capacity"*. Thanks to your work, **GPU capacity requirements were cut by ~75%**, which **enabled the feature to run within the approved GPU quota** for private preview. In fact, your one-prompt solution was expected to be so efficient that the Meeting Highlights preview **might not require any additional GPUs beyond the 130 already allocated** (a huge improvement from needing hundreds more). This was explicitly recognized in the project's work items: you were the **point-of-contact for "Improve LLM COGS / Prompt efficiency to meet Capacity Council requirements for GA"**, underlining your ownership of cost-reduction efforts.

## **Model & Pipeline Adjustments (Polymer → TMR)**

As part of implementing the new prompt, you also **migrated the generation pipeline from the legacy Polymer service to the newer TMR service**. This **removed an intermediate dependency** and allowed more direct integration with the LLM, improving efficiency. In initial planning, the team considered first moving the old multi-call prompt to TMR; however, under your guidance they **skipped directly to deploying the new single-prompt on TMR** to save time. This changeover simplified the architecture and will make it easier to plug in future model updates (for example, using Microsoft’s own smaller models) if needed. Notably, discussions with the capacity council also mentioned exploring **Microsoft’s Phi-4 model** as a long-term cost solution. While not implemented for GA due to timeline, the **Phi-4 small model was shown to cut COGS by \~80%** in similar scenarios without quality loss. Your work with the unified prompt lays the groundwork to potentially leverage such smaller models in the future, since the pipeline now expects a single LLM invocation (making it easier to swap in a different model if needed).

## **Quality Evaluation and Validation**

Throughout these optimizations, you carefully **validated that Meeting Highlights quality remained high**. You prepared a **dataset of meeting transcripts and expected highlights** to compare the old vs. new approach. In early October, after deploying the new prompt to a test environment, you conducted side-by-side evaluations with help from your team. This included:

*   **Manual testing (bug bashes):** You generated highlights for a variety of real meetings using your local tool and had team members review them qualitatively. This ensured the one-call prompt still captured key points and produced coherent video summaries.

*   **Automated metric evaluation (CoMet platform):** You worked with colleagues Amir Carmely and Dima to run both V1 and V2 outputs through an internal evaluation tool called **CoMet**. This measured metrics like **“grounding”** (factual accuracy) and **“coverage”** (how much of the important content is covered). The **baseline results for the original multi-prompt version were strong** – *grounding score was **very high**, and coverage about **75–80%***. You used these as a benchmark to ensure **no regression** with the new prompt. By Oct 7, you had resolved a few minor issues (e.g. *“level of details”* in summaries) and were generating final comparison data. The plan was to confirm that V2’s scores stay on par with V1’s – and early indications were positive (no major drops reported). In meetings, Oori Pen asked how quality differences are being checked; the team responded that **you are running thorough tests and will only proceed if the**“one-prompt” version shows no significant quality loss**. This careful evaluation gave leadership confidence that cost savings **did not come at the expense of user experience**.

*   **Pertinent results:** As of the last sync before private preview, **quality remained acceptable**. The team noted that with only two automated metrics (coverage and grounding) enabled, *“we have a good baseline”* and will expand metrics like level of detail once available. In other words, **your optimized prompt was producing highlights that were still highly factual and comprehensive**, closely matching the original version’s outputs. This was further supported by internal user feedback during the Microsoft-internal testing (“MSIT”), which remained positive (e.g. users continued to find the highlights a **“magical experience”** that saved them time) – implying no noticeable degradation in usefulness after your changes.

## **Impact on Release Timeline**

Your contributions were **directly responsible for unblocking the Meeting Highlights release**. Initially, the feature’s private preview was gated by capacity approval because of high GPU costs. By implementing the single-prompt optimization quickly, you allowed the team to move forward. In a project status meeting, it was stated that **“the bottleneck is not capacity anymore, but Evyatar finishing his changes… this will unblock the private preview and GA”**. Indeed, once you completed the prompt refactor and it proved successful in tests (targeted mid-October), the feature could begin **rolling out to Private Preview** users. Thanks to the massive cost reduction, the **capacity council approved Meeting Highlights with a much smaller GPU allotment** (the ask was trimmed from \~200 down to +50 GPUs), which is easily covered by the existing pool. The team noted that **with your optimizations, even 130 GPUs might handle private preview demand, and 180 should suffice for GA**. This was a huge win – as of mid-October 2025, management expected to start the private preview by Oct 22 (contingent on final tests), something made possible only by the cost savings you delivered.

Moreover, your work positions Meeting Highlights well for a **smooth worldwide rollout**. With COGS under control, leadership is no longer worried about business justification for the feature’s GPU usage. In the August meeting with the MSAI capacity council, one requirement was a *“plan to reduce costs as a fast follow”* – you provided exactly that plan and executed it. By **early October**, Kamini Sugumar (Product Lead) confirmed to stakeholders that **COGS concerns are addressed** (i.e., *“we’re good on the COGS front for Meeting Highlights”*, which was essentially the GPU question). This gave the green light to proceed with marketing and Ignite conference plans featuring Meeting Highlights as an upcoming capability.
***

**References from Internal Communications:** Your contributions are well documented in project artifacts and discussions. For example, the **project’s work item tracker** explicitly lists you as the owner for **“Improve LLM COGS/Prompt efficiency to meet Capacity Council requirements for GA”**. Meeting notes from Sept 30th record that **“Evyatar is doing a major change to reduce our capacity… changing the prompt from 4 LLM calls to 1 and reducing tokens”**. By Oct 7th, notes show you had **fixed merge issues after going from 4→1 prompt** and were generating evaluation datasets. The **GPU savings** are highlighted in a chat summary where it’s noted the **move to a single prompt** “*reduces the overall COGS we are using today*” and that **your change “practically cut the prompt 180°… it’s a huge change”**. In short, across emails, Teams chats, and meetings, there is clear recognition that **you led the prompt refactoring which slashed the feature’s GPU footprint and enabled its release**.

## **Bottom Line**

Through **prompt engineering and system tuning**, you **personally achieved an order-of-magnitude cost reduction for Meeting Highlights**, resolving the key blocker for release. You **merged four inference calls into one**, **trimmed prompt size**, and **updated the pipeline**, yielding roughly **75–80% GPU savings** while **maintaining high quality** (factual, comprehensive highlights). This work was completed on an aggressive timeline (within a few weeks), and it directly allowed Meeting Highlights to enter private preview with approval from the capacity council. Your technical leadership in reducing COGS not only unblocked the feature’s rollout but also demonstrated how thoughtful optimizations can deliver major efficiency gains **without compromising user experience**. These contributions were critical in positioning Meeting Highlights for a successful worldwide launch under acceptable cost and capacity limits