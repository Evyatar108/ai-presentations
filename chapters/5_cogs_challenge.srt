1
00:01:50,649 --> 00:01:54,570
Cost efficiency while maintaining quality is critical for scaling meeting highlights globally.

2
00:01:55,930 --> 00:02:01,450
The initial implementation required 4 sequential LLM calls per meeting, creating significant computational costs.

3
00:02:02,730 --> 00:02:08,851
This multi-step approach meant higher GPU requirements, estimated at around 600 GPUs to support global availability.

4
00:02:09,931 --> 00:02:15,171
Each additional prompt call added latency, complexity, and token overhead to the generation pipeline.

5
00:02:16,211 --> 00:02:22,932
To make Meeting Highlights economically viable at scale, we needed to dramatically reduce these computational costs without sacrificing quality.